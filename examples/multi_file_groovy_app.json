[
  {
    "jsonrpc": "2.0",
    "id": 1,
    "method": "tools/call",
    "params": {
      "name": "validate_code",
      "arguments": {
        "language": "groovy",
        "filename": "dsl.groovy",
        "save": true,
        "session_id": "groovy-task-automation",
        "code": "// DSL definitions and builders for task automation\nimport groovy.transform.CompileStatic\nimport groovy.transform.TupleConstructor\n\n// DSL Builder for creating tasks\nclass TaskDSL {\n    String name\n    String description\n    List<String> dependencies = []\n    Map<String, Object> config = [:]\n    Closure action\n    List<Closure> validators = []\n    \n    void name(String name) {\n        this.name = name\n    }\n    \n    void description(String desc) {\n        this.description = desc\n    }\n    \n    void dependsOn(String... deps) {\n        dependencies.addAll(deps)\n    }\n    \n    void configure(Map<String, Object> cfg) {\n        config.putAll(cfg)\n    }\n    \n    void validate(Closure validator) {\n        validators << validator\n    }\n    \n    void execute(Closure action) {\n        this.action = action\n    }\n    \n    // Method missing for dynamic configuration\n    def methodMissing(String name, args) {\n        if (args.length == 1) {\n            config[name] = args[0]\n        } else {\n            config[name] = args\n        }\n    }\n}\n\n// Pipeline DSL Builder\nclass PipelineDSL {\n    String name\n    List<TaskDSL> tasks = []\n    Map<String, Object> globalConfig = [:]\n    List<Closure> beforeTasks = []\n    List<Closure> afterTasks = []\n    \n    void pipeline(String name) {\n        this.name = name\n    }\n    \n    void globals(Map<String, Object> config) {\n        globalConfig.putAll(config)\n    }\n    \n    void beforeEach(Closure hook) {\n        beforeTasks << hook\n    }\n    \n    void afterEach(Closure hook) {\n        afterTasks << hook\n    }\n    \n    void task(String name, @DelegatesTo(TaskDSL) Closure closure) {\n        def taskDsl = new TaskDSL()\n        taskDsl.name = name\n        closure.delegate = taskDsl\n        closure.resolveStrategy = Closure.DELEGATE_FIRST\n        closure()\n        tasks << taskDsl\n    }\n    \n    // Support for creating task groups using spread operator\n    void taskGroup(String prefix, List<String> names, @DelegatesTo(TaskDSL) Closure template) {\n        names.each { name ->\n            task(\"${prefix}_${name}\", template)\n        }\n    }\n}\n\n// DSL Entry point factory\nclass DSLFactory {\n    static PipelineDSL createPipeline(@DelegatesTo(PipelineDSL) Closure closure) {\n        def pipeline = new PipelineDSL()\n        closure.delegate = pipeline\n        closure.resolveStrategy = Closure.DELEGATE_FIRST\n        closure()\n        return pipeline\n    }\n    \n    static TaskDSL createTask(@DelegatesTo(TaskDSL) Closure closure) {\n        def task = new TaskDSL()\n        closure.delegate = task\n        closure.resolveStrategy = Closure.DELEGATE_FIRST\n        closure()\n        return task\n    }\n}\n\nprintln '✓ dsl.groovy validated and saved'"
      }
    }
  },
  {
    "jsonrpc": "2.0",
    "id": 2,
    "method": "tools/call",
    "params": {
      "name": "validate_code",
      "arguments": {
        "language": "groovy",
        "filename": "models.groovy",
        "save": true,
        "session_id": "groovy-task-automation",
        "code": "// Task models and configurations for task automation system\nimport groovy.transform.*\nimport java.time.LocalDateTime\nimport java.time.Duration\n\n// Task status enum\nenum TaskStatus {\n    PENDING, RUNNING, SUCCESS, FAILED, SKIPPED\n}\n\n// Task execution result\n@TupleConstructor\n@ToString(includeNames = true)\nclass TaskResult {\n    TaskStatus status\n    String output\n    String error\n    LocalDateTime startTime\n    LocalDateTime endTime\n    Map<String, Object> metadata = [:]\n    \n    // Using Groovy truth\n    boolean isSuccess() {\n        status == TaskStatus.SUCCESS\n    }\n    \n    // Elvis operator for safe defaults\n    Duration getDuration() {\n        (startTime && endTime) ? Duration.between(startTime, endTime) : Duration.ZERO\n    }\n    \n    // GString interpolation\n    String getSummary() {\n        \"Task completed with status ${status} in ${duration.toMillis()}ms\"\n    }\n}\n\n// Task configuration\n@Builder\n@ToString(includeNames = true)\nclass TaskConfig {\n    String name\n    String description\n    List<String> dependencies = []\n    Map<String, Object> parameters = [:]\n    int maxRetries = 0\n    long timeoutMillis = 30000\n    boolean parallel = false\n    List<Closure> validators = []\n    \n    // Safe navigation operator example\n    String getParameterValue(String key, String defaultValue = null) {\n        parameters?.get(key)?.toString() ?: defaultValue\n    }\n    \n    // Collection enhancement: findAll with closure\n    List<String> getRequiredParameters() {\n        parameters.findAll { k, v -> v == null }.collect { it.key }\n    }\n}\n\n// Task definition\n@CompileStatic\nclass Task {\n    final String id\n    final TaskConfig config\n    final Closure action\n    TaskStatus status = TaskStatus.PENDING\n    TaskResult lastResult\n    List<TaskResult> history = []\n    \n    Task(String id, TaskConfig config, Closure action) {\n        this.id = id\n        this.config = config\n        this.action = action\n    }\n    \n    // Using spread operator\n    List<String> getAllDependencyIds() {\n        config.dependencies*.toLowerCase()\n    }\n    \n    void recordResult(TaskResult result) {\n        lastResult = result\n        history << result\n        status = result.status\n    }\n    \n    // Groovy truth and safe navigation\n    boolean canRun() {\n        status == TaskStatus.PENDING && config?.validators?.every { validator ->\n            try {\n                validator.call(config.parameters)\n            } catch (Exception e) {\n                false\n            }\n        }\n    }\n}\n\n// Pipeline execution context\nclass ExecutionContext {\n    final String pipelineId = UUID.randomUUID().toString()\n    final Map<String, Task> tasks = [:]\n    final Map<String, Object> globalVariables = [:]\n    final List<String> executionOrder = []\n    LocalDateTime startTime\n    LocalDateTime endTime\n    \n    // Using GString and collection methods\n    String getStatus() {\n        def taskStatuses = tasks.values()*.status.groupBy { it }\n        \"Pipeline ${pipelineId}: ${taskStatuses.collect { status, list -> \"${status}=${list.size()}\" }.join(', ')}\"\n    }\n    \n    // Safe navigation and Elvis operator\n    Task getTask(String taskId) {\n        tasks[taskId] ?: null\n    }\n    \n    // Spread operator to get all results\n    List<TaskResult> getAllResults() {\n        tasks.values()*.lastResult.findAll { it != null }\n    }\n    \n    // Using Groovy collections and closures\n    Map<TaskStatus, List<Task>> getTasksByStatus() {\n        tasks.values().groupBy { it.status }\n    }\n    \n    boolean isComplete() {\n        tasks.every { id, task -> \n            task.status in [TaskStatus.SUCCESS, TaskStatus.FAILED, TaskStatus.SKIPPED]\n        }\n    }\n}\n\n// Pipeline statistics\n@Canonical\nclass PipelineStats {\n    int totalTasks\n    int successfulTasks\n    int failedTasks\n    int skippedTasks\n    Duration totalDuration\n    Map<String, Duration> taskDurations = [:]\n    \n    static PipelineStats fromContext(ExecutionContext context) {\n        def stats = new PipelineStats()\n        def tasksByStatus = context.getTasksByStatus()\n        \n        stats.totalTasks = context.tasks.size()\n        stats.successfulTasks = tasksByStatus[TaskStatus.SUCCESS]?.size() ?: 0\n        stats.failedTasks = tasksByStatus[TaskStatus.FAILED]?.size() ?: 0\n        stats.skippedTasks = tasksByStatus[TaskStatus.SKIPPED]?.size() ?: 0\n        \n        // Calculate total duration with safe navigation\n        if (context.startTime && context.endTime) {\n            stats.totalDuration = Duration.between(context.startTime, context.endTime)\n        }\n        \n        // Collect task durations using collectEntries\n        stats.taskDurations = context.tasks.collectEntries { id, task ->\n            [(id): task.lastResult?.duration ?: Duration.ZERO]\n        }\n        \n        return stats\n    }\n    \n    // GString with formatting\n    String getSummary() {\n        \"\"\"Pipeline Statistics:\n        |  Total Tasks: ${totalTasks}\n        |  Successful: ${successfulTasks}\n        |  Failed: ${failedTasks}\n        |  Skipped: ${skippedTasks}\n        |  Total Duration: ${totalDuration?.toMillis() ?: 0}ms\n        |  Average Task Duration: ${getAverageDuration()}ms\n        \"\"\".stripMargin()\n    }\n    \n    long getAverageDuration() {\n        def durations = taskDurations.values().findAll { it.toMillis() > 0 }\n        durations ? (durations*.toMillis().sum() / durations.size()) as long : 0\n    }\n}\n\nprintln '✓ models.groovy validated and saved'"
      }
    }
  },
  {
    "jsonrpc": "2.0",
    "id": 3,
    "method": "tools/call",
    "params": {
      "name": "validate_code",
      "arguments": {
        "language": "groovy",
        "filename": "executor.groovy",
        "save": true,
        "session_id": "groovy-task-automation",
        "code": "// Task executor service for running pipeline tasks\nimport java.util.concurrent.*\nimport java.time.LocalDateTime\n\nclass TaskExecutor {\n    private final ExecutorService executorService\n    private final Map<String, List<Closure>> hooks = [:]\n    \n    TaskExecutor(int threadPoolSize = 4) {\n        this.executorService = Executors.newFixedThreadPool(threadPoolSize)\n        setupDefaultHooks()\n    }\n    \n    private void setupDefaultHooks() {\n        // Default logging hooks using closures\n        hooks['beforeTask'] = [\n            { task -> println \"[${LocalDateTime.now()}] Starting task: ${task.config.name}\" }\n        ]\n        hooks['afterTask'] = [\n            { task, result -> println \"[${LocalDateTime.now()}] Completed task: ${task.config.name} - ${result.status}\" }\n        ]\n        hooks['onError'] = [\n            { task, error -> println \"[${LocalDateTime.now()}] Error in task ${task.config.name}: ${error.message}\" }\n        ]\n    }\n    \n    void addHook(String event, Closure hook) {\n        hooks[event] = hooks[event] ?: []\n        hooks[event] << hook\n    }\n    \n    // Execute a single task\n    TaskResult executeTask(Task task, ExecutionContext context) {\n        // Run before hooks\n        hooks['beforeTask']?.each { it.call(task) }\n        \n        def result = new TaskResult(\n            startTime: LocalDateTime.now(),\n            status: TaskStatus.RUNNING,\n            metadata: [:]\n        )\n        \n        try {\n            // Check if task can run (validators)\n            if (!task.canRun()) {\n                result.status = TaskStatus.FAILED\n                result.error = \"Task validation failed\"\n                result.endTime = LocalDateTime.now()\n                return result\n            }\n            \n            // Check dependencies using Groovy collections\n            def failedDeps = task.getAllDependencyIds().findAll { depId ->\n                def dep = context.getTask(depId)\n                dep?.status != TaskStatus.SUCCESS\n            }\n            \n            if (failedDeps) {\n                result.status = TaskStatus.SKIPPED\n                result.output = \"Skipped due to failed dependencies: ${failedDeps.join(', ')}\"\n                result.endTime = LocalDateTime.now()\n                return result\n            }\n            \n            // Execute task action with timeout\n            def future = executorService.submit({\n                // Create task execution environment\n                def env = createTaskEnvironment(task, context)\n                \n                // Execute the task closure\n                def output = task.action.call(env)\n                return output\n            } as Callable)\n            \n            // Wait for completion with timeout\n            def output = future.get(task.config.timeoutMillis, TimeUnit.MILLISECONDS)\n            \n            result.status = TaskStatus.SUCCESS\n            result.output = output?.toString() ?: \"Task completed successfully\"\n            result.metadata['executionThread'] = Thread.currentThread().name\n            \n        } catch (TimeoutException e) {\n            result.status = TaskStatus.FAILED\n            result.error = \"Task timed out after ${task.config.timeoutMillis}ms\"\n            hooks['onError']?.each { it.call(task, e) }\n        } catch (Exception e) {\n            result.status = TaskStatus.FAILED\n            result.error = \"Task failed: ${e.message}\"\n            result.metadata['exceptionClass'] = e.class.simpleName\n            hooks['onError']?.each { it.call(task, e) }\n        } finally {\n            result.endTime = LocalDateTime.now()\n            task.recordResult(result)\n            \n            // Run after hooks\n            hooks['afterTask']?.each { it.call(task, result) }\n        }\n        \n        return result\n    }\n    \n    // Create task execution environment with access to context\n    private Map<String, Object> createTaskEnvironment(Task task, ExecutionContext context) {\n        [\n            // Task parameters\n            params: task.config.parameters,\n            \n            // Global variables\n            globals: context.globalVariables,\n            \n            // Utility methods using closures\n            log: { message -> println \"[${task.config.name}] ${message}\" },\n            \n            // Access to other task results using safe navigation\n            getTaskResult: { taskId -> context.getTask(taskId)?.lastResult },\n            \n            // Set global variable\n            setGlobal: { key, value -> context.globalVariables[key] = value },\n            \n            // Get global variable with Elvis operator\n            getGlobal: { key, defaultValue = null -> \n                context.globalVariables[key] ?: defaultValue \n            },\n            \n            // Task metadata\n            taskId: task.id,\n            taskName: task.config.name\n        ]\n    }\n    \n    // Execute pipeline with dependency resolution\n    PipelineStats executePipeline(ExecutionContext context) {\n        context.startTime = LocalDateTime.now()\n        \n        try {\n            // Build dependency graph and determine execution order\n            def executionPlan = buildExecutionPlan(context.tasks)\n            context.executionOrder.addAll(executionPlan)\n            \n            println \"\\nExecution plan: ${executionPlan.join(' -> ')}\"\n            \n            // Group tasks by dependency level for parallel execution\n            def taskLevels = groupTasksByLevel(context.tasks, executionPlan)\n            \n            // Execute tasks level by level\n            taskLevels.each { level, taskIds ->\n                println \"\\nExecuting level ${level}: ${taskIds.join(', ')}\"\n                \n                if (taskIds.size() == 1) {\n                    // Single task, execute directly\n                    def task = context.getTask(taskIds[0])\n                    executeTask(task, context)\n                } else {\n                    // Multiple tasks, execute in parallel if allowed\n                    def futures = taskIds.collect { taskId ->\n                        def task = context.getTask(taskId)\n                        if (task.config.parallel) {\n                            executorService.submit({\n                                executeTask(task, context)\n                            } as Callable<TaskResult>)\n                        } else {\n                            // Execute sequentially\n                            CompletableFuture.completedFuture(executeTask(task, context))\n                        }\n                    }\n                    \n                    // Wait for all tasks in this level to complete\n                    futures.each { it.get() }\n                }\n            }\n            \n        } finally {\n            context.endTime = LocalDateTime.now()\n        }\n        \n        return PipelineStats.fromContext(context)\n    }\n    \n    // Build execution plan using topological sort\n    private List<String> buildExecutionPlan(Map<String, Task> tasks) {\n        def visited = [:]\n        def result = []\n        \n        // Closure for DFS with Groovy's each\n        def visit\n        visit = { taskId ->\n            if (visited[taskId]) return\n            visited[taskId] = true\n            \n            def task = tasks[taskId]\n            task?.getAllDependencyIds()?.each { depId ->\n                if (tasks.containsKey(depId)) {\n                    visit(depId)\n                }\n            }\n            result << taskId\n        }\n        \n        // Visit all tasks\n        tasks.keySet().each { visit(it) }\n        \n        return result\n    }\n    \n    // Group tasks by execution level for parallel execution\n    private Map<Integer, List<String>> groupTasksByLevel(Map<String, Task> tasks, List<String> executionPlan) {\n        def levels = [:]\n        def taskLevels = [:]\n        \n        executionPlan.each { taskId ->\n            def task = tasks[taskId]\n            def deps = task.getAllDependencyIds().findAll { tasks.containsKey(it) }\n            \n            // Find the maximum level of dependencies\n            def maxDepLevel = deps.collect { taskLevels[it] ?: 0 }.max() ?: 0\n            def level = maxDepLevel + (deps ? 1 : 0)\n            \n            taskLevels[taskId] = level\n            levels[level] = levels[level] ?: []\n            levels[level] << taskId\n        }\n        \n        return levels.sort()\n    }\n    \n    void shutdown() {\n        executorService.shutdown()\n        try {\n            if (!executorService.awaitTermination(60, TimeUnit.SECONDS)) {\n                executorService.shutdownNow()\n            }\n        } catch (InterruptedException e) {\n            executorService.shutdownNow()\n        }\n    }\n}\n\nprintln '✓ executor.groovy validated and saved'"
      }
    }
  },
  {
    "jsonrpc": "2.0",
    "id": 4,
    "method": "tools/call",
    "params": {
      "name": "execute_code",
      "arguments": {
        "language": "groovy",
        "filename": "main.groovy",
        "save": true,
        "session_id": "groovy-task-automation",
        "code": "#!/usr/bin/env groovy\n// Main script demonstrating the task automation DSL\n\nprintln '=== GROOVY TASK AUTOMATION DSL DEMO ==='\nprintln()\n\n// Import our modules\nprintln 'Loading task automation framework...'\ntry {\n    // In a real scenario, these would be separate files\n    // For the demo, they're loaded in the session\n    println '✓ All modules loaded successfully'\n} catch (Exception e) {\n    println \"✗ Module loading failed: ${e.message}\"\n    System.exit(1)\n}\n\nprintln()\nprintln '=== DEFINING BUILD PIPELINE WITH DSL ==='\n\n// Create a build pipeline using our DSL\ndef buildPipeline = DSLFactory.createPipeline {\n    pipeline 'software-build'\n    \n    // Global configuration\n    globals(\n        projectName: 'AwesomeApp',\n        version: '1.0.0',\n        buildDir: '/tmp/build'\n    )\n    \n    // Before each task hook\n    beforeEach { task ->\n        println \"[HOOK] Preparing to run: ${task.config.name}\"\n    }\n    \n    // Define clean task\n    task('clean') {\n        description 'Clean build artifacts'\n        parallel true\n        timeoutMillis 5000\n        \n        execute { env ->\n            env.log \"Cleaning ${env.getGlobal('buildDir')}\"\n            Thread.sleep(500) // Simulate work\n            \"Cleaned build directory\"\n        }\n    }\n    \n    // Define compile task\n    task('compile') {\n        description 'Compile source code'\n        dependsOn 'clean'\n        \n        // Dynamic configuration using methodMissing\n        compiler 'groovyc'\n        sourceDir 'src/main/groovy'\n        optimization true\n        \n        validate { params ->\n            params.compiler != null\n        }\n        \n        execute { env ->\n            def compiler = env.params.compiler\n            env.log \"Compiling with ${compiler}...\"\n            Thread.sleep(1000) // Simulate compilation\n            env.setGlobal('compiledClasses', 150)\n            \"Compiled 150 classes successfully\"\n        }\n    }\n    \n    // Define test task\n    task('test') {\n        description 'Run unit tests'\n        dependsOn 'compile'\n        parallel false\n        \n        // Configuration using map\n        configure(\n            testFramework: 'spock',\n            includeIntegration: false\n        )\n        \n        execute { env ->\n            env.log \"Running tests with ${env.params.testFramework}\"\n            def compiledClasses = env.getGlobal('compiledClasses', 0)\n            \n            // Simulate test execution\n            Thread.sleep(1500)\n            \n            def testResults = [\n                total: 45,\n                passed: 43,\n                failed: 2,\n                skipped: 0\n            ]\n            \n            env.setGlobal('testResults', testResults)\n            \n            // Using GString and Groovy truth\n            if (testResults.failed) {\n                throw new RuntimeException(\"${testResults.failed} tests failed!\")\n            }\n            \n            \"All ${testResults.passed} tests passed!\"\n        }\n    }\n    \n    // Define package task\n    task('package') {\n        description 'Package application'\n        dependsOn 'compile'  // Note: doesn't depend on test\n        \n        execute { env ->\n            def version = env.getGlobal('version')\n            def projectName = env.getGlobal('projectName')\n            \n            env.log \"Creating ${projectName}-${version}.jar\"\n            Thread.sleep(800)\n            \n            def jarFile = \"${projectName}-${version}.jar\"\n            env.setGlobal('artifact', jarFile)\n            \n            \"Created ${jarFile} (2.3 MB)\"\n        }\n    }\n    \n    // Using task group with spread operator\n    taskGroup('validate', ['checkstyle', 'findbugs']) {\n        description { \"Run ${delegate.name} validation\" }\n        dependsOn 'compile'\n        parallel true\n        timeoutMillis 3000\n        \n        execute { env ->\n            def taskType = env.taskName.split('_')[1]\n            env.log \"Running ${taskType} analysis...\"\n            Thread.sleep(700)\n            \"${taskType} found ${(Math.random() * 10).toInteger()} issues\"\n        }\n    }\n    \n    // Deploy task\n    task('deploy') {\n        description 'Deploy to staging'\n        dependsOn 'package', 'test', 'validate_checkstyle', 'validate_findbugs'\n        \n        // Deployment configuration\n        server 'staging.example.com'\n        deployPath '/opt/apps'\n        \n        validate { params ->\n            // Using safe navigation and Elvis operator\n            params.server?.trim() ?: false\n        }\n        \n        execute { env ->\n            def artifact = env.getGlobal('artifact', 'unknown.jar')\n            def server = env.params.server\n            \n            env.log \"Deploying ${artifact} to ${server}\"\n            Thread.sleep(2000)\n            \n            \"Successfully deployed to ${server}\"\n        }\n    }\n}\n\nprintln()\nprintln '=== CREATING EXECUTION CONTEXT ==='\n\n// Convert DSL to executable tasks\ndef context = new ExecutionContext()\ncontext.globalVariables.putAll(buildPipeline.globalConfig)\n\n// Convert DSL tasks to Task objects\nbuildPipeline.tasks.each { taskDsl ->\n    def config = TaskConfig.builder()\n        .name(taskDsl.name)\n        .description(taskDsl.description ?: \"Task ${taskDsl.name}\")\n        .dependencies(taskDsl.dependencies)\n        .parameters(taskDsl.config)\n        .validators(taskDsl.validators)\n        .parallel(taskDsl.config.parallel ?: false)\n        .timeoutMillis(taskDsl.config.timeoutMillis ?: 30000)\n        .build()\n    \n    def task = new Task(taskDsl.name, config, taskDsl.action)\n    context.tasks[taskDsl.name] = task\n}\n\nprintln \"Created ${context.tasks.size()} tasks\"\nprintln \"Tasks: ${context.tasks.keySet().sort().join(', ')}\"\n\nprintln()\nprintln '=== EXECUTING PIPELINE ==='\n\n// Create executor and run pipeline\ndef executor = new TaskExecutor(4)\n\n// Add custom hooks\nexecutor.addHook('afterTask') { task, result ->\n    if (result.isSuccess()) {\n        println \"✓ ${task.config.name}: ${result.output}\"\n    } else {\n        println \"✗ ${task.config.name}: ${result.error ?: result.output}\"\n    }\n}\n\ntry {\n    def stats = executor.executePipeline(context)\n    \n    println()\n    println '=== PIPELINE EXECUTION COMPLETE ==='\n    println stats.summary\n    \n    println()\n    println '=== TASK DETAILS ==='\n    \n    // Using spread operator and safe navigation\n    context.tasks.values()*.with { task ->\n        def result = task.lastResult\n        println \"\\n${task.config.name}:\"\n        println \"  Status: ${task.status}\"\n        println \"  Duration: ${result?.duration?.toMillis() ?: 0}ms\"\n        if (result?.output) {\n            println \"  Output: ${result.output}\"\n        }\n        if (result?.error) {\n            println \"  Error: ${result.error}\"\n        }\n    }\n    \n    println()\n    println '=== GLOBAL VARIABLES ==='\n    context.globalVariables.each { key, value ->\n        println \"  ${key}: ${value}\"\n    }\n    \n} finally {\n    executor.shutdown()\n}\n\nprintln()\nprintln '=== DEMONSTRATING GROOVY DSL FEATURES ==='\n\n// Create a simple task using DSL\ndef quickTask = DSLFactory.createTask {\n    name 'quick-demo'\n    description 'Demonstrate Groovy features'\n    \n    // Dynamic property setting\n    inputFile '/tmp/data.txt'\n    outputFormat 'json'\n    compressionLevel 9\n    \n    execute { env ->\n        // Collection enhancements\n        def numbers = [1, 2, 3, 4, 5]\n        def doubled = numbers.collect { it * 2 }\n        def evens = numbers.findAll { it % 2 == 0 }\n        \n        // Spread operator\n        def names = ['Alice', 'Bob', 'Charlie']\n        def upperNames = names*.toUpperCase()\n        \n        // Safe navigation and Elvis\n        def config = env.params\n        def format = config?.outputFormat ?: 'xml'\n        def level = config?.compressionLevel ?: 5\n        \n        // GStrings\n        \"\"\"Groovy Features Demo:\n        |  Doubled numbers: ${doubled}\n        |  Even numbers: ${evens}\n        |  Uppercase names: ${upperNames.join(', ')}\n        |  Output format: ${format}\n        |  Compression: ${level}\n        \"\"\".stripMargin()\n    }\n}\n\n// Execute the quick task\ndef quickConfig = TaskConfig.builder()\n    .name(quickTask.name)\n    .description(quickTask.description)\n    .parameters(quickTask.config)\n    .build()\n\ndef quickTaskObj = new Task('quick-demo', quickConfig, quickTask.action)\ndef quickContext = new ExecutionContext()\nquickContext.tasks[quickTaskObj.id] = quickTaskObj\n\ndef quickResult = executor.executeTask(quickTaskObj, quickContext)\nprintln()\nprintln quickResult.output\n\nprintln()\nprintln '✅ Groovy Task Automation DSL demo completed!'\nprintln()\nprintln '🔧 Key Groovy features demonstrated:'\nprintln '  • DSL building with closures and delegates'\nprintln '  • Method missing for dynamic configuration'\nprintln '  • Safe navigation (?.) and Elvis (?:) operators'\nprintln '  • Spread operator (*.) for collections'\nprintln '  • GStrings for string interpolation'\nprintln '  • Collection enhancements (collect, findAll, groupBy)'\nprintln '  • Groovy truth for boolean evaluation'\nprintln '  • Builder pattern and @DelegatesTo'\nprintln()\nprintln '🔄 All files persist within this container session'\nprintln '🗑️  Files will be cleaned up when container restarts'\nprintln '🔒 Host system remains completely isolated'"
      }
    }
  }
]